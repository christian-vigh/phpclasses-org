<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
    <title></title>
</head>
<body>
<div>

<div itemprop="articleBody">
	<h2>Contents</h2>
	<h3>Introduction</h3>
	<h3>Methodology</h3>
	<h3>Conclusion</h3>

	<h2>Introduction</h2>
	<div>
		We are all happy when we succeed in designing a code implementation that satisfies our initial goals and presents a good
		modular and object-oriented approach. We test it on data sets that have hundreds, thousands or even tenths of thousands items.
		<br />
		But what happens when we go into the real world and exercise our code with hundreds of thousands real-world items, or even millions ?
		we may found that our conceptually beautiful design is... terribly slow !
		<br /><br />
		This article gives some hints and clues on where to start and what you can do when you discover that your code has performance issues.
		<br />
		Clear (and small) examples of commonly encountered situations will be given, together with a suggested solution to obtain performance gains.<br />
		All these examples can be run as standalone command-line PHP scripts, which is a faster way than the design-implement-publish-view cycle involved by web
		application development.
		<br /><br />
		Only PHP aspects will be covered here ; database performance issues, which can fall into at least four categories (schema optimization, 
		query optimization, database API usage and database server configuration) spread a pretty much wider scope that may be covered one day by future articles...
	</div>

	<h2>Methodology</h2>
	<div>
		Well, <i>methodology</i> may sound like a pedantic word when you're in a <i>don't panic !</i> situation. However, it's always a good thing 
		to know that you can get valuable help from existing free tools, such as profilers, which help you to identify performance bottlenecks.
		<br />
		<h3>Getting help from analysis tools</h3>

		Profilers are always a good start to measure the execution time of your code. They take your code, insert their own extra code to measure execution time 
		at chosen places, then generate a profiling data file when you run your program or script. This data file contains measurement statistics about your 
		code execution, that you can later view and analyze using a profiling data viewer application.
		<br /><br />

			<h4>The xdebug profiler</h4>

			<h4>Profiling data file viewers</h4>

		<h3>How and when should you profile your code ?</h3>
		The answer to the <i>When ?</i> is prettily straightforward : profile your code when you notice that it is terribly slow...<br /><br />
		The <i>How ?</i> requires more attention from you : you must be aware that profiling some code adds significant overhead during execution.<br />
		As an example, consider the following when you're using the <b>xdebug</b> extension :
		<ul>
			<li>Simply enabling the <b>xdebug</b> extension in your <i>php.ini</i> file without enabling profiling can make your code run slower.</li>
			<li>Enabling the <b>xdebug</b> extension to profile your code makes it run slower by another factor of 20 to 40.</li>
		</ul>
		yes, you read it : profiling your code can make it run slower by a factor of 40 ! (of course, this may not exactly be 40 : it 
		depends on your code and your execution environment, so just consider these numbers as an order of magnitude).<br /><br />
		Given that, if your real-world data contains several millions of items, don't even think about using a profiler on them ! <br /><br />
		What I would suggest in such situations is the following :
		<ol>
			<li>
				Try to :
				<ul>
					<li>make your real-world code to work only on a few thousands of items <i>or...</i></li>
					<li>extract the code responsible for bad performance and put it in a standalone script ; make it work on a few thousand items</li>
				</ul>
			</li>
			<li>Profile your code and analyze the results with a viewer. You will see where you spend most of the time.</li>
			<li>Optimize the parts of code that take most of the execution time, getting inspiration from the hints and clues given later in this article,
			    and don't forget that your own experience is by itself a great source of inspiration</li>
			<li>Profile again</li>
			<li>Once satisfied with the results, test your modifications with real-world data <b>without profiling</b>.</li>
			<li>
				If performance results are still not satisfying, then maybe :
				<ul>
					<li>The code you isolated at step 1 is not representative of the real-world conditions <i>or...</i></li>
					<li>The data set you chosed is not representative of the real-world conditions or is too small to give reliable
						performance data
					</li>
				</ul>
				In any case, review your sampling and start again with step 1.
			</li>
		</ol>

		<h3>Where benchmarking comes to rescue</h3>

		Benchmarking is an important task because it helps you to time processes accomplishing certain tasks, and identify the potential overhead 
		implied by your operating system. <br /><br />
		Benchmarking is not profiling : benchmarking is here to get an overall idea of the execution times of a process on particular hardware and 
		software configurations, while profiling is the process of identifying the parts of your code that consume most of the execution time.<br /><br />
		But why talking about benchmarking here ?<br /><br />
		Benchmarking can measure several things, but three of the possible values it can measure are common and fundamental to all benchmarks :
		<ul>
			<li><i>User cpu time</i> : this is the total time spent in your user's code</li>
			<li><i>System cpu time</i> : the total time spent in the kernel code. When you open a file, read its contents, send a network packet, etc.
				the execution time taken by the system function you are calling is accounted as system cpu time.
			</li>
			<li><i>Elapsed time</i> : the difference between the time your program stopped and the time it was started</li>
		</ul>
		This is where benchmarking brings an important notion : the operating system can put some unwanted overhead on your program's execution. On an idle
		configuration (ie, a platform with only a minimum number of running processes, and a system idle time near to 100%), user cpu time + system cpu time
		<i>should</i> be near elapsed time.<br /><br />
		But on an heavily loaded system, these quantities may vary, and elapsed time may be much larger than the sum of user + system time.<br /><br />
		Of course, things that may impact elapsed execution time can vary ; it may be :
		<ul>
			<li>Waiting for user input (well, this would not be a good idea to benchmark or profile such code)</li>
			<li>Access to slow resources (cdroms, slow networks, etc.)</li>
			<li>Entering a sleep loop or waiting for a mutex to be freed</li>
		</ul>
		Generally, such situations give a really low user + system time when compared to the overall elapsed time, so we won't consider all of them as "benchmarkable".
		<br /><br />
		Heavily loaded systems will naturally make your program run slower, impacting elapsed execution time as well as system cpu time. Reasons for that can come from 
		(among other reasons) :
		<ul>
			<li>Multiple processes consuming cpu time several times per second. On most OSes, process (context) switching is a very expensive operation
				(you have to save registers, page descriptors, stack state and much other things before giving control to the process that is being
				switched to)
			</li>
			<li>Swapping. Swapping occurs when your system memory is too small to hold all the memory allocation requests coming from the running processes.
				When this happens, the system has to put some parts of the RAM back and forth a special disk space called <i>swap space</i> (on Unix brands)
				or <i>pagefile</i> (Windows) before restoring a given process' address space.
			</li>
		</ul>
		Depending on the OS you're running, parts of this OS-housekeeping tasks can be wrongly accounted into your program's system cpu time.<br /><br />
		When you're running Unix, the <i>time</i> command gives you such information ; simply put "time" before the command you want to run, as in :<br /><br />

		<code>time php myscript.php</code>
		<br /><br />

		On Windows platforms, you will be a little bit unlucky, unless you have Cygwin installed.<br /><br />
		This leads me to the two following topics :

		<ul>
			<li>Choosing an appropriate execution time for the code to be profiled</li>
			<li>Estimating your operating system overhead</li>
		</ul>

		<h3>Choosing an appropriate execution time</h3>
		Hey, what does this mean ? <br /><br />
		Given the considerations exposed in the preceding paragraph, it becomes clear that the faster runs the code you profiled, the greater can be the
		part occupied by system cpu time.<br /><br />
		I have seen many execution results from people who tried to optimize their code, that gave something like that :<br /><br />
		<code>
			execution time before optimization : 0.050s<br />
			execution time after optimization : 0.020s<br />
			performance gain : 40%<br />
		</code>
		<br />
		Forget that : you will <b>NEVER</b> be able to time correctly the execution time of a process that takes only a few tenths of milliseconds to execute. 
		If you try to run it twenty times, you will get twenty different results that can differ by several hundreds of <i>percents</i>, due to the small amount
		of time needed to run the code, and the proportion that can be accounted to the system cpu time.
		<br /><br />
		When benchmarking/profiling a program, be sure that you feed it with sufficient data so that its execution can last at least a few seconds and provide
		you with consistent execution times from one execution to another.<br /><br />
		Of course, due to the amount of overhead implied when profiling a program, I suggest that you start with runs that last only a few seconds (without profiling) ;
		otherwise you would lose significant time in the <i>profile -> analyze -> optimize -> profile</i> loop.<br /><br />
		Once your optimization task is complete, I suggest that you perform a last try with a data set that makes your program run during, say, several seconds or minutes
		(without enabling profiling), just in the case you did not cover all the optimization issues that could have been hidden with smaller data sets.

		<h3>Estimating your operating system overhead</h3>
		You can easily measure operating system overhead using the Unix <i>time</i> command ; Windows platforms users will have to use the tools provided
		with their development environments or the utilities they have downloaded to time program execution.<br /><br />
		There is however a platform-independent way that allows you to time several executions of the same function and give you some comparative values regarding
		execution times ; the <i>measure_delta()</i> function below is an example on how you can do that ; it takes as a parameter a callback function
		(the function you want to optimize) and a number of executions to perform.<br />
		It gives as output the min/max execution times (in seconds dot milliseconds) and the deviation in percentage for the min/max execution times :<br />
		<code><pre>
	function  measure_delta ( $func, $measurements = 10 )
	   {
		$min_runtime 	=  PHP_INT_MAX ;
		$max_runtime 	=  -PHP_INT_MAX ;
		
		echo ( "Trying to evaluate measurement accuracy of $func :\n" ) ;
		
		for  ( $i = 0 ; $i  <  $measurements ; $i ++ )
		   {
			$start_time 		=  microtime ( true ) ;
		
			call_user_func ( $func ) ;
		
			$end_time 		=  microtime ( true ) ;
			$delta 			=  $end_time - $start_time ;
			
			if  ( $min_runtime > $delta )
				$min_runtime 	=  $delta ;
			
			if  ( $max_runtime  <  $delta )
				$max_runtime 	=  $delta ;
		    }
		    
		$delta 		=  $max_runtime - $min_runtime ;
		$percent1 	=  round ( ( 100 / $min_runtime ) *  $delta, 2 ) ;
		$percent2 	=  round ( ( 100 / $max_runtime ) *  $delta, 2 ) ;
		
		echo ( "\tMin elapsed : " . number_format ( $min_runtime, 3, '.', ' ' ) . "\n" ) ;
		echo ( "\tMax elapsed : " . number_format ( $max_runtime, 3, '.', ' ' ) . "\n" ) ;
		echo ( "\tDelta       : " . number_format ( $delta, 3, '.', ' ' ) . "\n" ) ;
		
		echo ( "Accuracy is between " . min ( $percent1, $percent2 ) . "% and " . 
						max ( $percent1, $percent2 ) . "%\n" ) ;
	    }</pre></code>

		Then develop some function to be timed (here a function that performs the sum of all the elements of a 3-million items array) :

		<code><pre>
	function  slow_sum_array ( )
	   {
		$array 		=  range ( 0, 3000000 ) ;
		$total 		=  0.0 ;
		
		for  ( $i = 0 ; $i  <  count ( $array ) ; $i ++ )
			$total += $array [$i] ;
	    }</pre></code>

		And finally, call the measurement function :

		<code><pre>	measure_delta ( 'slow_sum_array' ) ;</pre></code>

		These were the results on an heavily loaded Windows 7 system :

		<code><pre>
	Trying to evaluate measurement accuracy of slow_sum_array :
		Min elapsed : 2.393
		Max elapsed : 4.770
		Delta       : 2.377
	Accuracy is between 49.83% and 99.31%
		      </pre></code>

		Oops ! the delta between min and max execution times represents between 50% (of max execution time) and almost 100% (of min execution time).<br />
		These results are too erratic to be reliable ; the same program can take twice the time it would do depending on the OS load, although the code
		to execute does not make any system calls (it just adds values from an array). This is not an acceptable situation for benchmarking or profiling your
		code, so you will have to find a less busy platform for your optimization task.<br /><br />
		Here are the results I got on not-so-busy Windows and Unix platforms :

		<code><pre>
	Trying to evaluate measurement accuracy of slow_sum_array :
		Min elapsed : 2.467
		Max elapsed : 2.680
		Delta       : 0.213
	Accuracy is between 7.95% and 8.63%</pre></code>

		This is not perfect but less than 10% "random" overhead becomes acceptable for our analysis tasks.

		<h2>Conclusion</h2>
		This article introduced a few basic principles to be used when trying to optimize code. It also presented some useful tools for 
	</div>
</div>

</div>
</body>
</html>
